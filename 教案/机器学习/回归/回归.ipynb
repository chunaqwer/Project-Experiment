{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 机器学习- 回归"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 单变量线性回归"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#轮到你了\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['font.sans-serif']=['SimHei'] #用来正常显示中文标签\n",
    "plt.rcParams['axes.unicode_minus']=False #用来正常显示负号\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#轮到你了\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "path = 'data/regress_data1.csv'\n",
    "data = pd.read_csv(path)\n",
    "data.head()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#轮到你了\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "# 查看数据信息\n",
    "data.describe()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#轮到你了\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "看下数据长什么样子\n",
    "```python\n",
    "data.plot(kind='scatter', x='人口', y='收益', figsize=(12,8)) # 散点图\n",
    "plt.xlabel('人口', fontsize=18) # x轴\n",
    "plt.ylabel('收益', rotation=0, fontsize=18) # y轴\n",
    "plt.show()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#轮到你了\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "现在让我们使用梯度下降来实现线性回归，以最小化代价函数。 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "首先，我们将创建一个以参数$w$为特征函数的代价函数\n",
    "$$J\\left( w  \\right)=\\frac{1}{2m}\\sum\\limits_{i=1}^{m}{{{\\left( {{h}}\\left( {{x}^{(i)}} \\right)-{{y}^{(i)}} \\right)}^{2}}}$$\n",
    "其中：\\\\[{{h}}\\left( x \\right)={{w}^{T}}X={{w }_{0}}{{x}_{0}}+{{w }_{1}}{{x}_{1}}+{{w }_{2}}{{x}_{2}}+...+{{w }_{n}}{{x}_{n}}\\\\] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "def computeCost(X, y, w):\n",
    "    inner = np.power(((X * w.T) - y), 2)# (m,n) @ (n, 1) -> (n, 1)\n",
    "#     return np.sum(inner) / (2 * len(X))\n",
    "    return np.sum(inner) / (2 * X.shape[0])\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#轮到你了\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "让我们在训练集中添加一列，以便我们可以使用向量化的解决方案来计算代价和梯度。\n",
    "```python\n",
    "data.insert(0, 'Ones', 1)\n",
    "data\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#轮到你了\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "现在我们来做一些变量初始化。\n",
    "```python\n",
    "# set X (training data) and y (target variable)\n",
    "cols = data.shape[1]\n",
    "X = data.iloc[:,:cols-1] #X是所有行，去掉最后一列\n",
    "y = data.iloc[:,cols-1:] #X是所有行，最后一列\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#轮到你了\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "# 查看X、y维度\n",
    "X.shape, y.shape\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#轮到你了\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "观察下 X (训练集) and y (目标变量)是否正确.\n",
    "```python\n",
    "X.head() #head()是观察前5行\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#轮到你了\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "y.head()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#轮到你了\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "代价函数应该是numpy矩阵，所以我们需要转换X和Y，然后才能使用它们。 我们还需要初始化w。\n",
    "```python\n",
    "X = np.matrix(X.values)\n",
    "y = np.matrix(y.values)\n",
    "w = np.matrix(np.array([0,0]))\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#轮到你了\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "w 是一个(1,2)矩阵\n",
    "```python\n",
    "print(w) # 或者 w\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#轮到你了\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "看下维度\n",
    "```python\n",
    "X.shape, w.shape, y.shape\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#轮到你了\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "计算代价函数 (theta初始值为0).\n",
    "```python\n",
    "computeCost(X, y, w)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#轮到你了\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Batch Gradient Decent（批量梯度下降）\n",
    "\n",
    "$${{w }_{j}}:={{w }_{j}}- \\alpha \\frac{1}{m}\\sum\\limits_{i=1}^m \\frac{\\partial }{\\partial {{w}_{j}}}J\\left( w \\right)$$\n",
    "```python\n",
    "def batch_gradientDescent(X, y, w, alpha, iters):\n",
    "    temp = np.matrix(np.zeros(w.shape))\n",
    "    parameters = int(w.ravel().shape[1])\n",
    "    cost = np.zeros(iters)\n",
    "\n",
    "    for i in range(iters):\n",
    "        error = (X * w.T) - y\n",
    "\n",
    "        for j in range(parameters):\n",
    "            term = np.multiply(error, X[:, j])\n",
    "            temp[0, j] = w[0, j] - ((alpha / len(X)) * np.sum(term))\n",
    "\n",
    "        w = temp\n",
    "        cost[i] = computeCost(X, y, w)\n",
    "\n",
    "    return w, cost\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#轮到你了\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "初始化一些附加变量 - 学习速率α和要执行的迭代次数。\n",
    "```python\n",
    "alpha = 0.01\n",
    "iters = 1000\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#轮到你了\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "现在让我们运行梯度下降算法来将我们的参数θ适合于训练集。\n",
    "```python\n",
    "g, cost = batch_gradientDescent(X, y, w, alpha, iters)\n",
    "g\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#轮到你了\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "最后，我们可以使用我们拟合的参数计算训练模型的代价函数（误差）。\n",
    "```python\n",
    "computeCost(X, y, g)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#轮到你了\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "现在我们来绘制线性模型以及数据，直观地看出它的拟合。\n",
    "```python\n",
    "x = np.linspace(data['人口'].min(), data['人口'].max(), 100)\n",
    "f = g[0, 0] + (g[0, 1] * x)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "ax.plot(x, f, 'r', label='预测值')\n",
    "ax.scatter(data['人口'], data['收益'], label='训练数据')\n",
    "ax.legend(loc=2)\n",
    "ax.set_xlabel('人口', fontsize=18)\n",
    "ax.set_ylabel('收益', rotation=0, fontsize=18)\n",
    "ax.set_title('预测收益和人口规模', fontsize=18)\n",
    "plt.show()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#轮到你了\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "由于梯度方程式函数也在每个训练迭代中输出一个代价的向量，所以我们也可以绘制。 请注意，代价总是降低 - 这是凸优化问题的一个例子。\n",
    "```python\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "ax.plot(np.arange(iters), cost, 'r')\n",
    "ax.set_xlabel('迭代次数', fontsize=18)\n",
    "ax.set_ylabel('代价', rotation=0, fontsize=18)\n",
    "ax.set_title('误差和训练Epoch数', fontsize=18)\n",
    "plt.show()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#轮到你了\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 多变量线性回归"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "练习还包括一个房屋价格数据集，其中有2个变量（房子的大小，卧室的数量）和目标（房子的价格）。 我们使用我们已经应用的技术来分析数据集。\n",
    "```python\n",
    "path = 'data/regress_data2.csv'\n",
    "data2 = pd.read_csv(path)\n",
    "data2.head()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#轮到你了\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对于此任务，我们添加了另一个预处理步骤 - 特征归一化。 这个对于pandas来说很简单\n",
    "```python\n",
    "data2 = (data2 - data2.mean()) / data2.std()\n",
    "data2.head()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#轮到你了\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "现在我们重复第1部分的预处理步骤，并对新数据集运行线性回归程序。\n",
    "```python\n",
    "# add ones column\n",
    "data2.insert(0, 'Ones', 1)\n",
    "\n",
    "# set X (training data) and y (target variable)\n",
    "cols = data2.shape[1]\n",
    "X2 = data2.iloc[:,0:cols-1]\n",
    "y2 = data2.iloc[:,cols-1:cols]\n",
    "\n",
    "# convert to matrices and initialize theta\n",
    "X2 = np.matrix(X2.values)\n",
    "y2 = np.matrix(y2.values)\n",
    "w2 = np.matrix(np.array([0,0,0]))\n",
    "\n",
    "# perform linear regression on the data set\n",
    "g2, cost2 = batch_gradientDescent(X2, y2, w2, alpha, iters)\n",
    "\n",
    "# get the cost (error) of the model\n",
    "computeCost(X2, y2, g2)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#轮到你了\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们也可以快速查看这一个的训练进程。\n",
    "```python\n",
    "fig, ax = plt.subplots(figsize=(12,8))\n",
    "ax.plot(np.arange(iters), cost2, 'r')\n",
    "ax.set_xlabel('迭代次数', fontsize=18)\n",
    "ax.set_ylabel('代价', rotation=0, fontsize=18)\n",
    "ax.set_title('误差和训练Epoch数', fontsize=18)\n",
    "plt.show()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#轮到你了\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们也可以使用scikit-learn的线性回归函数，而不是从头开始实现这些算法。 我们将scikit-learn的线性回归算法应用于第1部分的数据，并看看它的表现。\n",
    "```python\n",
    "from sklearn.linear_model import LinearRegression\n",
    "model = LinearRegression()\n",
    "model.fit(X, y)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#轮到你了\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "scikit-learn model的预测表现\n",
    "```python\n",
    "x = np.array(X[:, 1].A1)\n",
    "f = model.predict(X).flatten()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "ax.plot(x, f, 'r', label='预测值')\n",
    "ax.scatter(data['人口'], data['收益'], label='训练数据')\n",
    "ax.legend(loc=2, fontsize=18)\n",
    "ax.set_xlabel('人口', fontsize=18)\n",
    "ax.set_ylabel('收益', rotation=0, fontsize=18)\n",
    "ax.set_title('预测收益和人口规模', fontsize=18)\n",
    "plt.show()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#轮到你了\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $L_2$正则化\n",
    "$J (  { w } ) = \\frac { 1 } { 2 } \\sum _ { i = 1 } ^ { m } ( h _ { w} ( x ^ { ( i ) } ) - y ^ { ( i ) } ) ^ { 2 } + \\lambda \\sum _ { j = 1 } ^ { n } w_ { j } ^ { 2 }$，此时称作`Ridge Regression`：\n",
    "```python\n",
    "from sklearn.linear_model import Ridge\n",
    "model = Ridge()\n",
    "model.fit(X, y)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#轮到你了\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "x2 = np.array(X[:, 1].A1)\n",
    "f2 = model.predict(X).flatten()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "ax.plot(x2, f2, 'r', label='预测值Ridge')\n",
    "ax.scatter(data['人口'], data['收益'], label='训练数据')\n",
    "ax.legend(loc=2, fontsize=18)\n",
    "ax.set_xlabel('人口', fontsize=18)\n",
    "ax.set_ylabel('收益', rotation=0, fontsize=18)\n",
    "ax.set_title('预测收益和人口规模', fontsize=18)\n",
    "plt.show()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#轮到你了\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $L_1$正则化：\n",
    "$J (  {w } ) = \\frac { 1 } { 2 } \\sum _ { i = 1 } ^ { m } ( h _ { w} ( x ^ { ( i ) } ) - y ^ { ( i ) } ) ^ { 2 } + \\lambda \\sum _ { j = 1 } ^ { n } | w _ { j } |$，此时称作`Lasso Regression` \n",
    "```python\n",
    "from sklearn.linear_model import Lasso\n",
    "model = Lasso()\n",
    "model.fit(X, y)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#轮到你了\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "x3= np.array(X[:, 1].A1)\n",
    "f3 = model.predict(X).flatten()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "ax.plot(x3, f3, 'r', label='预测值Lasso')\n",
    "ax.scatter(data['人口'], data['收益'], label='训练数据')\n",
    "ax.legend(loc=2, fontsize=18)\n",
    "ax.set_xlabel('人口', fontsize=18)\n",
    "ax.set_ylabel('收益', rotation=0, fontsize=18)\n",
    "ax.set_title('预测收益和人口规模', fontsize=18)\n",
    "plt.show()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#轮到你了\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 调参\n",
    "\n",
    "```python\n",
    "from sklearn.model_selection import cross_val_score\n",
    "alphas = np.logspace(-3, 2, 50)\n",
    "test_scores = []\n",
    "for alpha in alphas:\n",
    "    clf = Ridge(alpha)\n",
    "    test_score = np.sqrt(-cross_val_score(clf, X, y, cv=5, scoring='neg_mean_squared_error'))\n",
    "    test_scores.append(np.mean(test_score))\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(alphas, test_scores)\n",
    "plt.title(\"Alpha vs CV Error\");\n",
    "plt.show()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#轮到你了\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 最小二乘法(LSM)：\n",
    "\n",
    "最小二乘法的需要求解最优参数$w^{*}$：\n",
    "\n",
    "已知：目标函数\n",
    "\n",
    "$J\\left( w  \\right)=\\frac{1}{2m}\\sum\\limits_{i=1}^{m}{{{\\left( {h}\\left( {x^{(i)}} \\right)-{y^{(i)}} \\right)}^{2}}}$\n",
    "\n",
    "其中：${h}\\left( x \\right)={w^{T}}X={w_{0}}{x_{0}}+{w_{1}}{x_{1}}+{w_{2}}{x_{2}}+...+{w_{n}}{x_{n}}$\n",
    "\n",
    "将向量表达形式转为矩阵表达形式，则有$J(w )=\\frac{1}{2}{{\\left( Xw -y\\right)}^{2}}$ ，其中$X$为$m$行$n+1$列的矩阵（$m$为样本个数，$n$为特征个数），$w$为$n+1$行1列的矩阵(包含了$w_0$)，$y$为$m$行1列的矩阵，则可以求得最优参数$w^{*} ={{\\left( {X^{T}}X \\right)}^{-1}}{X^{T}}y$ \n",
    "\n",
    "梯度下降与最小二乘法的比较：\n",
    "\n",
    "梯度下降：需要选择学习率$\\alpha$，需要多次迭代，当特征数量$n$大时也能较好适用，适用于各种类型的模型\t\n",
    "\n",
    "最小二乘法：不需要选择学习率$\\alpha$，一次计算得出，需要计算${{\\left( {{X}^{T}}X \\right)}^{-1}}$，如果特征数量$n$较大则运算代价大，因为矩阵逆的计算时间复杂度为$O(n^3)$，通常来说当$n$小于10000 时还是可以接受的，只适用于线性模型，不适合逻辑回归模型等其他模型\n",
    "\n",
    "```python\n",
    "def LSM(X, y):\n",
    "    w = np.linalg.inv(X.T@X)@X.T@y#X.T@X等价于X.T.dot(X)\n",
    "    return w\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#轮到你了\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "final_w2=LSM(X, y)#感觉和批量梯度下降的theta的值有点差距\n",
    "final_w2\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#轮到你了\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 梯度下降得到的结果是matrix([[-3.24140214,  1.1272942 ]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
